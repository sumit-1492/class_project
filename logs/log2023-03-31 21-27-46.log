[2023-03-31 21:27:50,817] root - INFO - Training pipleine config: TrainingPipelineConfig(artifact_dir='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact')
[2023-03-31 21:27:50,818] root - INFO - Data Ingestion config: DataIngestionConfig(dataset_download_url='https://raw.githubusercontent.com/Shivan118/Main-Branching/main/Visadataset.csv', raw_data_dir='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-27-46\\raw_data', ingested_train_dir='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-27-46\\ingested_data\\train', ingested_test_dir='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-27-46\\ingested_data\\test')
[2023-03-31 21:27:50,819] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Ingestion log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 


[2023-03-31 21:27:50,819] root - INFO - Downloading file from :[https://raw.githubusercontent.com/Shivan118/Main-Branching/main/Visadataset.csv] into :[c:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-27-46\raw_data\Visadataset.csv]
[2023-03-31 21:27:52,065] root - INFO - File :[c:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-27-46\raw_data\Visadataset.csv] has been downloaded successfully.
[2023-03-31 21:27:52,065] root - INFO - Reading csv file: [c:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-27-46\raw_data\Visadataset.csv]
[2023-03-31 21:27:52,146] root - INFO - Splitting data into train and test
[2023-03-31 21:27:52,155] root - INFO - Exporting training dataset to file: [c:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-27-46\ingested_data\train\Visadataset.csv]
[2023-03-31 21:27:52,241] root - INFO - Exporting test dataset to file: [c:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-27-46\ingested_data\test\Visadataset.csv]
[2023-03-31 21:27:52,261] root - INFO - Data Ingestion artifact:[DataIngestionArtifact(train_file_path='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-27-46\\ingested_data\\train\\Visadataset.csv', test_file_path='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-27-46\\ingested_data\\test\\Visadataset.csv', is_ingested=True, message='Data ingestion completed successfully.')]
[2023-03-31 21:27:52,263] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Validation log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 


[2023-03-31 21:27:52,286] root - INFO - Validation Process Started
[2023-03-31 21:27:52,575] root - INFO - Train_set status|is Train filename validated?: True|is train columns validated?: True|is train column name validated?: True|whole missing columns?True
[2023-03-31 21:27:52,575] root - INFO - Test_set status|is Test filename validated?: Trueis test col numbers validated?: True|is test column names validated? True| whole missing columns? True
[2023-03-31 21:27:52,575] root - INFO - Validation Process Completed
[2023-03-31 21:27:52,575] root - INFO - Data validation artifact: DataValidationArtifact(schema_file_path='c:\\Users\\shiva\\Desktop\\test2\\project_template\\config\\schema.yaml', is_validated=True, message='Data validation performed')
[2023-03-31 21:27:52,575] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Validation log completed.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-03-31 21:27:52,576] root - INFO - Data transformation config: DataTransformationConfig(transformed_train_dir='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-27-46\\transformed_data\\train', transformed_test_dir='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-27-46\\transformed_data\\test', preprocessed_object_file_path='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-27-46\\preprocessed\\preprocessed.pkl')
[2023-03-31 21:27:52,576] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Transformation log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-03-31 21:27:52,576] root - INFO - Obtaining preprocessing object.
[2023-03-31 21:27:52,589] root - INFO - Obtaining training and test file path.
[2023-03-31 21:27:52,590] root - INFO - Loading training and test data as pandas dataframe.
[2023-03-31 21:27:52,703] root - INFO - Outlier capped in train df
[2023-03-31 21:27:52,709] root - INFO - Outlier capped in test df
[2023-03-31 21:27:52,710] root - INFO - Splitting input and target feature from training and testing dataframe.
[2023-03-31 21:27:52,763] root - INFO - Applying preprocessing object on training dataframe and testing dataframe.
[2023-03-31 21:28:20,896] root - INFO - Saving transformed training and test array.
[2023-03-31 21:28:20,908] root - INFO - Saving preprocessing object.
[2023-03-31 21:28:20,945] root - INFO - Data transformation artifact: DataTransformationArtifact(is_transformed=True, message='Data transformation successfull.', transformed_train_file_path='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-27-46\\transformed_data\\train\\Visadataset.npz', transformed_test_file_path='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-27-46\\transformed_data\\test\\Visadataset.npz', preprocessed_object_file_path='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-27-46\\preprocessed\\preprocessed.pkl')
[2023-03-31 21:28:20,952] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Transformation log completed.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 


[2023-03-31 21:28:20,954] root - INFO - Model trainer config: ModelTrainerConfig(trained_model_file_path='c:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\model_trainer\\2023-03-31-21-27-46\\trained_model\\model.pkl', base_accuracy=0.6, model_config_file_path='config\\model.yaml')
[2023-03-31 21:28:20,954] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Model trainer log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 
[2023-03-31 21:28:20,954] root - INFO - Loading transformed training dataset
[2023-03-31 21:28:20,989] root - INFO - Loading transformed testing dataset
[2023-03-31 21:28:21,026] root - INFO - Splitting training and testing input and target feature
[2023-03-31 21:28:21,026] root - INFO - Extracting model config file path
[2023-03-31 21:28:21,026] root - INFO - Initializing model factory class using above model config file: config\model.yaml
[2023-03-31 21:28:52,228] root - INFO - Expected accuracy: 0.6
[2023-03-31 21:28:53,736] root - INFO - Initiating operation model selection
[2023-03-31 21:28:55,984] root - INFO - Started Initializing model from config file
[2023-03-31 21:28:55,986] root - INFO - Executing command: from <module 'sklearn.ensemble' from 'C:\\Application\\anaconda\\envs\\travelling\\lib\\site-packages\\sklearn\\ensemble\\__init__.py'> import RandomForestClassifier
[2023-03-31 21:28:55,996] root - INFO - Executing:$ RandomForestClassifier().max_depth=0.1
[2023-03-31 21:28:55,998] root - INFO - Executing:$ RandomForestClassifier(max_depth=0.1).max_features=5
[2023-03-31 21:28:56,000] root - INFO - Executing:$ RandomForestClassifier(max_depth=0.1, max_features=5).min_samples_split=2
[2023-03-31 21:28:56,001] root - INFO - Executing:$ RandomForestClassifier(max_depth=0.1, max_features=5).n_estimators=100
[2023-03-31 21:28:56,001] root - INFO - Executing command: from <module 'sklearn.neighbors' from 'C:\\Application\\anaconda\\envs\\travelling\\lib\\site-packages\\sklearn\\neighbors\\__init__.py'> import KNeighborsClassifier
[2023-03-31 21:28:56,002] root - INFO - Executing:$ KNeighborsClassifier().n_neighbors=2
[2023-03-31 21:28:56,003] root - INFO - Executing:$ KNeighborsClassifier(n_neighbors=2).weights=uniform
[2023-03-31 21:28:56,005] root - INFO - Initialized model: [InitializedModelDetail(model_serial_number='module_0', model=RandomForestClassifier(max_depth=0.1, max_features=5), param_grid_search={'min_samples_split': [2, 8, 15], 'max_features': [5, 'sqrt', 'log2'], 'n_estimators': [100, 200, 1000], 'max_depth': [5, 8, 10]}, model_name='sklearn.ensemble.RandomForestClassifier'), InitializedModelDetail(model_serial_number='module_1', model=KNeighborsClassifier(n_neighbors=2), param_grid_search={'n_neighbors': [3, 5, 9, 11], 'weights': ['uniform', 'distance']}, model_name='sklearn.neighbors.KNeighborsClassifier')]
[2023-03-31 21:28:56,006] root - INFO - Executing command: from <module 'sklearn.model_selection' from 'C:\\Application\\anaconda\\envs\\travelling\\lib\\site-packages\\sklearn\\model_selection\\__init__.py'> import GridSearchCV
[2023-03-31 21:28:56,010] root - INFO - Executing:$ GridSearchCV(estimator=RandomForestClassifier(max_depth=0.1, max_features=5),
             param_grid={'max_depth': [5, 8, 10],
                         'max_features': [5, 'sqrt', 'log2'],
                         'min_samples_split': [2, 8, 15],
                         'n_estimators': [100, 200, 1000]}).cv=2
[2023-03-31 21:28:56,015] root - INFO - Executing:$ GridSearchCV(cv=2,
             estimator=RandomForestClassifier(max_depth=0.1, max_features=5),
             param_grid={'max_depth': [5, 8, 10],
                         'max_features': [5, 'sqrt', 'log2'],
                         'min_samples_split': [2, 8, 15],
                         'n_estimators': [100, 200, 1000]}).verbose=2
[2023-03-31 21:28:56,015] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> f"Training RandomForestClassifier Started." <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
