[2023-03-31 21:05:46,353] root - INFO - Training pipleine config: TrainingPipelineConfig(artifact_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact')
[2023-03-31 21:05:46,353] root - INFO - Data Ingestion config: DataIngestionConfig(dataset_download_url='https://raw.githubusercontent.com/Shivan118/Main-Branching/main/Visadataset.csv', raw_data_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-05-40\\raw_data', ingested_train_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-05-40\\ingested_data\\train', ingested_test_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-05-40\\ingested_data\\test')
[2023-03-31 21:05:46,353] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Ingestion log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 


[2023-03-31 21:05:46,354] root - INFO - Downloading file from :[https://raw.githubusercontent.com/Shivan118/Main-Branching/main/Visadataset.csv] into :[C:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-05-40\raw_data\Visadataset.csv]
[2023-03-31 21:05:47,574] root - INFO - File :[C:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-05-40\raw_data\Visadataset.csv] has been downloaded successfully.
[2023-03-31 21:05:47,574] root - INFO - Reading csv file: [C:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-05-40\raw_data\Visadataset.csv]
[2023-03-31 21:05:47,645] root - INFO - Splitting data into train and test
[2023-03-31 21:05:47,651] root - INFO - Exporting training dataset to file: [C:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-05-40\ingested_data\train\Visadataset.csv]
[2023-03-31 21:05:47,717] root - INFO - Exporting test dataset to file: [C:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-05-40\ingested_data\test\Visadataset.csv]
[2023-03-31 21:05:47,733] root - INFO - Data Ingestion artifact:[DataIngestionArtifact(train_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-05-40\\ingested_data\\train\\Visadataset.csv', test_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-05-40\\ingested_data\\test\\Visadataset.csv', is_ingested=True, message='Data ingestion completed successfully.')]
[2023-03-31 21:05:47,735] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Validation log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 


[2023-03-31 21:05:47,740] root - INFO - Validation Process Started
[2023-03-31 21:05:48,005] root - INFO - Train_set status|is Train filename validated?: True|is train columns validated?: True|is train column name validated?: True|whole missing columns?True
[2023-03-31 21:05:48,006] root - INFO - Test_set status|is Test filename validated?: Trueis test col numbers validated?: True|is test column names validated? True| whole missing columns? True
[2023-03-31 21:05:48,006] root - INFO - Validation Process Completed
[2023-03-31 21:05:48,006] root - INFO - Data validation artifact: DataValidationArtifact(schema_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\config\\schema.yaml', is_validated=True, message='Data validation performed')
[2023-03-31 21:05:48,006] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Validation log completed.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-03-31 21:05:48,006] root - INFO - Data transformation config: DataTransformationConfig(transformed_train_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-05-40\\transformed_data\\train', transformed_test_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-05-40\\transformed_data\\test', preprocessed_object_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-05-40\\preprocessed\\preprocessed.pkl')
[2023-03-31 21:05:48,006] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Transformation log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-03-31 21:05:48,006] root - INFO - Obtaining preprocessing object.
[2023-03-31 21:05:48,013] root - INFO - Obtaining training and test file path.
[2023-03-31 21:05:48,013] root - INFO - Loading training and test data as pandas dataframe.
[2023-03-31 21:05:48,128] root - INFO - Outlier capped in train df
[2023-03-31 21:05:48,130] root - INFO - Outlier capped in test df
[2023-03-31 21:05:48,130] root - INFO - Splitting input and target feature from training and testing dataframe.
[2023-03-31 21:05:48,158] root - INFO - Applying preprocessing object on training dataframe and testing dataframe.
[2023-03-31 21:06:12,313] root - INFO - Saving transformed training and test array.
[2023-03-31 21:06:12,321] root - INFO - Saving preprocessing object.
[2023-03-31 21:06:12,336] root - INFO - Data transformation artifact: DataTransformationArtifact(is_transformed=True, message='Data transformation successfull.', transformed_train_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-05-40\\transformed_data\\train\\Visadataset.npz', transformed_test_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-05-40\\transformed_data\\test\\Visadataset.npz', preprocessed_object_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-05-40\\preprocessed\\preprocessed.pkl')
[2023-03-31 21:06:12,343] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Transformation log completed.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 


[2023-03-31 21:06:12,343] root - INFO - Model trainer config: ModelTrainerConfig(trained_model_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\model_trainer\\2023-03-31-21-05-40\\trained_model\\model.pkl', base_accuracy=0.6, model_config_file_path='config\\model.yaml')
[2023-03-31 21:06:12,343] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Model trainer log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 
[2023-03-31 21:06:12,343] root - INFO - Loading transformed training dataset
[2023-03-31 21:06:12,359] root - INFO - Loading transformed testing dataset
[2023-03-31 21:06:12,394] root - INFO - Splitting training and testing input and target feature
[2023-03-31 21:06:12,394] root - INFO - Extracting model config file path
[2023-03-31 21:06:12,394] root - INFO - Initializing model factory class using above model config file: config\model.yaml
[2023-03-31 21:06:12,401] root - INFO - Expected accuracy: 0.6
[2023-03-31 21:06:12,401] root - INFO - Initiating operation model selection
[2023-03-31 21:06:12,401] root - INFO - Started Initializing model from config file
[2023-03-31 21:06:12,401] root - INFO - Executing command: from <module 'sklearn.ensemble' from 'C:\\Application\\anaconda\\envs\\travelling\\lib\\site-packages\\sklearn\\ensemble\\__init__.py'> import RandomForestClassifier
[2023-03-31 21:06:12,409] root - INFO - Executing:$ RandomForestClassifier().max_depth=0.1
[2023-03-31 21:06:12,409] root - INFO - Executing:$ RandomForestClassifier(max_depth=0.1).max_features=5
[2023-03-31 21:06:12,410] root - INFO - Executing:$ RandomForestClassifier(max_depth=0.1, max_features=5).min_samples_split=2
[2023-03-31 21:06:12,410] root - INFO - Executing:$ RandomForestClassifier(max_depth=0.1, max_features=5).n_estimators=100
[2023-03-31 21:06:12,410] root - INFO - Executing command: from <module 'sklearn.neighbors' from 'C:\\Application\\anaconda\\envs\\travelling\\lib\\site-packages\\sklearn\\neighbors\\__init__.py'> import KNeighborsClassifier
[2023-03-31 21:06:12,411] root - INFO - Executing:$ KNeighborsClassifier().n_neighbors=2
[2023-03-31 21:06:12,411] root - INFO - Executing:$ KNeighborsClassifier(n_neighbors=2).weights=uniform
[2023-03-31 21:06:12,412] root - INFO - Initialized model: [InitializedModelDetail(model_serial_number='module_0', model=RandomForestClassifier(max_depth=0.1, max_features=5), param_grid_search={'min_samples_split': [2, 8, 15], 'max_features': [5, 'sqrt', 'log2'], 'n_estimators': [100, 200, 1000], 'max_depth': [5, 8, 10]}, model_name='sklearn.ensemble.RandomForestClassifier'), InitializedModelDetail(model_serial_number='module_1', model=KNeighborsClassifier(n_neighbors=2), param_grid_search={'n_neighbors': [3, 5, 9, 11], 'weights': ['uniform', 'distance']}, model_name='sklearn.neighbors.KNeighborsClassifier')]
[2023-03-31 21:06:12,412] root - INFO - Executing command: from <module 'sklearn.model_selection' from 'C:\\Application\\anaconda\\envs\\travelling\\lib\\site-packages\\sklearn\\model_selection\\__init__.py'> import GridSearchCV
[2023-03-31 21:06:12,415] root - INFO - Executing:$ GridSearchCV(estimator=RandomForestClassifier(max_depth=0.1, max_features=5),
             param_grid={'max_depth': [5, 8, 10],
                         'max_features': [5, 'sqrt', 'log2'],
                         'min_samples_split': [2, 8, 15],
                         'n_estimators': [100, 200, 1000]}).cv=2
[2023-03-31 21:06:12,417] root - INFO - Executing:$ GridSearchCV(cv=2,
             estimator=RandomForestClassifier(max_depth=0.1, max_features=5),
             param_grid={'max_depth': [5, 8, 10],
                         'max_features': [5, 'sqrt', 'log2'],
                         'min_samples_split': [2, 8, 15],
                         'n_estimators': [100, 200, 1000]}).verbose=2
[2023-03-31 21:06:12,417] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> f"Training RandomForestClassifier Started." <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
