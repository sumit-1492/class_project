[2023-03-31 21:11:36,338] root - INFO - Training pipleine config: TrainingPipelineConfig(artifact_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact')
[2023-03-31 21:11:36,339] root - INFO - Data Ingestion config: DataIngestionConfig(dataset_download_url='https://raw.githubusercontent.com/Shivan118/Main-Branching/main/Visadataset.csv', raw_data_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-11-33\\raw_data', ingested_train_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-11-33\\ingested_data\\train', ingested_test_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-11-33\\ingested_data\\test')
[2023-03-31 21:11:36,341] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Ingestion log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 


[2023-03-31 21:11:36,342] root - INFO - Downloading file from :[https://raw.githubusercontent.com/Shivan118/Main-Branching/main/Visadataset.csv] into :[C:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-11-33\raw_data\Visadataset.csv]
[2023-03-31 21:11:36,648] root - INFO - File :[C:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-11-33\raw_data\Visadataset.csv] has been downloaded successfully.
[2023-03-31 21:11:36,649] root - INFO - Reading csv file: [C:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-11-33\raw_data\Visadataset.csv]
[2023-03-31 21:11:36,720] root - INFO - Splitting data into train and test
[2023-03-31 21:11:36,727] root - INFO - Exporting training dataset to file: [C:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-11-33\ingested_data\train\Visadataset.csv]
[2023-03-31 21:11:36,808] root - INFO - Exporting test dataset to file: [C:\Users\shiva\Desktop\test2\project_template\us_visa\artifact\data_ingestion\2023-03-31-21-11-33\ingested_data\test\Visadataset.csv]
[2023-03-31 21:11:36,828] root - INFO - Data Ingestion artifact:[DataIngestionArtifact(train_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-11-33\\ingested_data\\train\\Visadataset.csv', test_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_ingestion\\2023-03-31-21-11-33\\ingested_data\\test\\Visadataset.csv', is_ingested=True, message='Data ingestion completed successfully.')]
[2023-03-31 21:11:36,830] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Validation log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 


[2023-03-31 21:11:36,854] root - INFO - Validation Process Started
[2023-03-31 21:11:37,117] root - INFO - Train_set status|is Train filename validated?: True|is train columns validated?: True|is train column name validated?: True|whole missing columns?True
[2023-03-31 21:11:37,117] root - INFO - Test_set status|is Test filename validated?: Trueis test col numbers validated?: True|is test column names validated? True| whole missing columns? True
[2023-03-31 21:11:37,117] root - INFO - Validation Process Completed
[2023-03-31 21:11:37,117] root - INFO - Data validation artifact: DataValidationArtifact(schema_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\config\\schema.yaml', is_validated=True, message='Data validation performed')
[2023-03-31 21:11:37,118] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Validation log completed.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-03-31 21:11:37,118] root - INFO - Data transformation config: DataTransformationConfig(transformed_train_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-11-33\\transformed_data\\train', transformed_test_dir='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-11-33\\transformed_data\\test', preprocessed_object_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-11-33\\preprocessed\\preprocessed.pkl')
[2023-03-31 21:11:37,119] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Transformation log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-03-31 21:11:37,119] root - INFO - Obtaining preprocessing object.
[2023-03-31 21:11:37,132] root - INFO - Obtaining training and test file path.
[2023-03-31 21:11:37,132] root - INFO - Loading training and test data as pandas dataframe.
[2023-03-31 21:11:37,249] root - INFO - Outlier capped in train df
[2023-03-31 21:11:37,254] root - INFO - Outlier capped in test df
[2023-03-31 21:11:37,254] root - INFO - Splitting input and target feature from training and testing dataframe.
[2023-03-31 21:11:37,304] root - INFO - Applying preprocessing object on training dataframe and testing dataframe.
[2023-03-31 21:11:56,390] root - INFO - Saving transformed training and test array.
[2023-03-31 21:11:56,400] root - INFO - Saving preprocessing object.
[2023-03-31 21:11:56,423] root - INFO - Data transformation artifact: DataTransformationArtifact(is_transformed=True, message='Data transformation successfull.', transformed_train_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-11-33\\transformed_data\\train\\Visadataset.npz', transformed_test_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-11-33\\transformed_data\\test\\Visadataset.npz', preprocessed_object_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\data_transformation\\2023-03-31-21-11-33\\preprocessed\\preprocessed.pkl')
[2023-03-31 21:11:56,425] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Data Transformation log completed.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 


[2023-03-31 21:11:56,425] root - INFO - Model trainer config: ModelTrainerConfig(trained_model_file_path='C:\\Users\\shiva\\Desktop\\test2\\project_template\\us_visa\\artifact\\model_trainer\\2023-03-31-21-11-33\\trained_model\\model.pkl', base_accuracy=0.6, model_config_file_path='config\\model.yaml')
[2023-03-31 21:11:56,425] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Model trainer log started.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< 
[2023-03-31 21:11:56,426] root - INFO - Loading transformed training dataset
[2023-03-31 21:11:56,447] root - INFO - Loading transformed testing dataset
[2023-03-31 21:11:56,480] root - INFO - Splitting training and testing input and target feature
[2023-03-31 21:11:56,480] root - INFO - Extracting model config file path
[2023-03-31 21:11:56,481] root - INFO - Initializing model factory class using above model config file: config\model.yaml
[2023-03-31 21:11:56,498] root - INFO - Expected accuracy: 0.6
[2023-03-31 21:11:56,498] root - INFO - Initiating operation model selection
[2023-03-31 21:12:10,900] root - INFO - Started Initializing model from config file
[2023-03-31 21:12:44,758] root - INFO - Executing command: from <module 'sklearn.ensemble' from 'C:\\Application\\anaconda\\envs\\travelling\\lib\\site-packages\\sklearn\\ensemble\\__init__.py'> import RandomForestClassifier
[2023-03-31 21:12:44,761] root - INFO - Executing:$ RandomForestClassifier().max_depth=0.1
[2023-03-31 21:12:44,763] root - INFO - Executing:$ RandomForestClassifier(max_depth=0.1).max_features=5
[2023-03-31 21:12:44,764] root - INFO - Executing:$ RandomForestClassifier(max_depth=0.1, max_features=5).min_samples_split=2
[2023-03-31 21:12:44,765] root - INFO - Executing:$ RandomForestClassifier(max_depth=0.1, max_features=5).n_estimators=100
[2023-03-31 21:12:44,765] root - INFO - Executing command: from <module 'sklearn.neighbors' from 'C:\\Application\\anaconda\\envs\\travelling\\lib\\site-packages\\sklearn\\neighbors\\__init__.py'> import KNeighborsClassifier
[2023-03-31 21:12:44,769] root - INFO - Executing:$ KNeighborsClassifier().n_neighbors=2
[2023-03-31 21:12:44,770] root - INFO - Executing:$ KNeighborsClassifier(n_neighbors=2).weights=uniform
[2023-03-31 21:12:44,773] root - INFO - Initialized model: [InitializedModelDetail(model_serial_number='module_0', model=RandomForestClassifier(max_depth=0.1, max_features=5), param_grid_search={'min_samples_split': [2, 8, 15], 'max_features': [5, 'sqrt', 'log2'], 'n_estimators': [100, 200, 1000], 'max_depth': [5, 8, 10]}, model_name='sklearn.ensemble.RandomForestClassifier'), InitializedModelDetail(model_serial_number='module_1', model=KNeighborsClassifier(n_neighbors=2), param_grid_search={'n_neighbors': [3, 5, 9, 11], 'weights': ['uniform', 'distance']}, model_name='sklearn.neighbors.KNeighborsClassifier')]
[2023-03-31 21:12:44,774] root - INFO - Executing command: from <module 'sklearn.model_selection' from 'C:\\Application\\anaconda\\envs\\travelling\\lib\\site-packages\\sklearn\\model_selection\\__init__.py'> import GridSearchCV
[2023-03-31 21:12:44,782] root - INFO - Executing:$ GridSearchCV(estimator=RandomForestClassifier(max_depth=0.1, max_features=5),
             param_grid={'max_depth': [5, 8, 10],
                         'max_features': [5, 'sqrt', 'log2'],
                         'min_samples_split': [2, 8, 15],
                         'n_estimators': [100, 200, 1000]}).cv=2
[2023-03-31 21:12:44,785] root - INFO - Executing:$ GridSearchCV(cv=2,
             estimator=RandomForestClassifier(max_depth=0.1, max_features=5),
             param_grid={'max_depth': [5, 8, 10],
                         'max_features': [5, 'sqrt', 'log2'],
                         'min_samples_split': [2, 8, 15],
                         'n_estimators': [100, 200, 1000]}).verbose=2
[2023-03-31 21:12:44,786] root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> f"Training RandomForestClassifier Started." <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
